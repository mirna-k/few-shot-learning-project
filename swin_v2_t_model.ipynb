{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Few-shot-learning using swin_v2_t pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXLvBqVRCD_x"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/mirna-k/few-shot-learning-project.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TEPu3IGtl1e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "from easyFSL_helper import *\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPXmW6DM1ce8"
      },
      "outputs": [],
      "source": [
        "dataset_path = '/content/few-shot-learning-project/animals_dataset'\n",
        "labelmap_path = '/content/few-shot-learning-project/animals_label_map.json'\n",
        "\n",
        "N = 10 # n_classes\n",
        "K = 5  # n_support_images\n",
        "n_query = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGOiGy-WtrW9"
      },
      "outputs": [],
      "source": [
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((180, 180)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YtYYg3x1rI3"
      },
      "outputs": [],
      "source": [
        "class ClassData:\n",
        "    def __init__(self, support_dir, query_dir, class_name, label, cro_name, description, transform=None):\n",
        "        self.class_name = class_name\n",
        "        self.label = label\n",
        "        self.cro_name = cro_name\n",
        "        self.description = description\n",
        "        self.images = []\n",
        "\n",
        "        support_images_paths = [os.path.join(support_dir, filename) for filename in os.listdir(support_dir)]\n",
        "        query_images_paths = [os.path.join(query_dir, filename) for filename in os.listdir(query_dir)]\n",
        "\n",
        "        for image_path in support_images_paths:\n",
        "            image = Image.open(image_path)\n",
        "            if transform:\n",
        "                image = transform(image)\n",
        "            self.images.append(image)\n",
        "\n",
        "        for image_path in query_images_paths:\n",
        "            image = Image.open(image_path)\n",
        "            if transform:\n",
        "                image = transform(image)\n",
        "            self.images.append(image)\n",
        "\n",
        "        self.images = torch.stack(self.images)\n",
        "        self.len = len(self.images)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "    @classmethod\n",
        "    def get_class_data(cls, dataset_dir, class_label_map_json, transform=None):\n",
        "        sets = {}\n",
        "\n",
        "        with open(class_label_map_json, 'r') as f:\n",
        "            class_label_map = json.load(f)\n",
        "\n",
        "        for class_name, attributes in class_label_map.items():\n",
        "            label = attributes['label']\n",
        "            cro_name = attributes['cro_name']\n",
        "            description = attributes['description']\n",
        "\n",
        "            class_dir = os.path.join(dataset_dir, class_name)\n",
        "            if os.path.isdir(class_dir):\n",
        "                support_dir = os.path.join(class_dir, \"support\")\n",
        "                query_dir = os.path.join(class_dir, \"query\")\n",
        "                sets[label] = cls(support_dir, query_dir, class_name, label, cro_name, description, transform)\n",
        "\n",
        "        return sets\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, class_data):\n",
        "        self.class_data = class_data\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "\n",
        "        for label, data in class_data.items():\n",
        "            self.images.extend(data.images)\n",
        "            self.labels.extend([label] * len(data))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQ99sXJ8ybGn"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "\n",
        "class_data = ClassData.get_class_data(dataset_path, labelmap_path, val_transform)\n",
        "dataset = CustomDataset(class_data)\n",
        "\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "model = models.swin_v2_t(weights=models.Swin_V2_T_Weights.IMAGENET1K_V1)\n",
        "\n",
        "model.head = nn.Flatten()\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duOI4IdR42uu"
      },
      "outputs": [],
      "source": [
        "embeddings_df = predict_embeddings(data_loader, model, device=device)\n",
        "\n",
        "print(embeddings_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "UO14wiEB8Rc6"
      },
      "outputs": [],
      "source": [
        "features_dataset = FeaturesDataset.from_dataframe(embeddings_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZlgMgzQ_yLS"
      },
      "outputs": [],
      "source": [
        "task_sampler = TaskSampler(features_dataset, n_way=N, n_shot=K, n_query=n_query, n_tasks=100)\n",
        "\n",
        "features_loader = DataLoader(features_dataset, batch_sampler=task_sampler, pin_memory=True, collate_fn=task_sampler.episodic_collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qJJnpJdALec"
      },
      "outputs": [],
      "source": [
        "few_shot_classifier = PrototypicalNetworks(backbone=nn.Identity())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vrd24lEyAMIp"
      },
      "outputs": [],
      "source": [
        "accuracy, macro_precision, macro_recall = evaluate(few_shot_classifier, features_loader, device=\"cpu\")\n",
        "\n",
        "print(f\"Average accuracy : {(100 * accuracy):.6f} %\\nMacro precision: {(100 * macro_precision):.6f}%\\nMacro recall: {(100 * macro_recall):.6f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_fyxRV1XziR"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "\n",
        "def plot_images(images: Tensor, title: str, images_per_row: int):\n",
        "    plt.figure()\n",
        "    plt.title(title)\n",
        "    plt.imshow(torchvision.utils.make_grid(images, nrow=images_per_row).permute(1, 2, 0))\n",
        "\n",
        "\n",
        "dataset.get_labels = lambda: [instance for instance in dataset.labels]\n",
        "\n",
        "task_sampler = TaskSampler(dataset, n_way=N, n_shot=K, n_query=n_query, n_tasks=100)\n",
        "support_loader =  DataLoader(dataset, batch_sampler=task_sampler, pin_memory=True, collate_fn=task_sampler.episodic_collate_fn)\n",
        "\n",
        "(support_images, support_labels, query_images, query_labels, class_ids,) = next(iter(support_loader))\n",
        "\n",
        "plot_images(support_images, \"support images\", images_per_row=K)\n",
        "plot_images(query_images, \"query images\", images_per_row=n_query)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
